{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWGxq2HWEUbrbhVZAGgLGn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhakrishnan-omotec/fundus-repo/blob/main/Fundus_ImageClassification_Project_7_classes_IMAGE_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN based ResNet152 Image Classification for highest accuracy in google Colab notebook format"
      ],
      "metadata": {
        "id": "W5kH3OBiOzL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a complete Google Colab notebook for implementing a ResNet152-based image classification model for the highest accuracy, tailored to classify 5 classes of fundus images (e.g., Diabetic Retinopathy stages) using a dataset of approximately 3,700 images. ResNet152 is chosen for its deep architecture and residual connections, which excel in extracting intricate features from complex medical images. The notebook includes data loading, preprocessing, model training, evaluation, and visualization, optimized for Colab’s GPU environment.\n",
        "\n",
        "Since you referenced a prior context (3,700 fundus images with 5 classes), I’ll assume the dataset is structured with subfolders for each class (e.g., No_DR, Mild, Moderate, Severe, Proliferative_DR) in a Google Drive directory. Adjust paths and class names as needed."
      ],
      "metadata": {
        "id": "5rEGzW9BO3p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet152 for Fundus Image Classification"
      ],
      "metadata": {
        "id": "anazaJA4O7GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet152 for Fundus Image Classification\n",
        "\n",
        "This notebook implements a ResNet152-based Convolutional Neural Network (CNN) for classifying fundus images into 5 Diabetic Retinopathy classes using a dataset of ~3,700 images. ResNet152, with its 152 layers and residual connections, is selected for its superior accuracy in medical imaging tasks. The workflow includes data loading from Google Drive, preprocessing with augmentation, transfer learning, training on a GPU, and evaluation. The goal is to maximize classification accuracy for deployment in diagnostic applications.\n",
        "\n",
        "### Workflow\n",
        "1. Setup and import libraries.\n",
        "2. Load and preprocess the dataset.\n",
        "3. Define and configure ResNet152.\n",
        "4. Train the model.\n",
        "5. Evaluate and visualize results."
      ],
      "metadata": {
        "id": "uvhVdCv7O-f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Setup and Import Libraries"
      ],
      "metadata": {
        "id": "hxeD6wA7O_dv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_BAh8KuOufV"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Setup and Imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Enable GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.test.is/gpu_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load and Preprocess the Dataset"
      ],
      "metadata": {
        "id": "EyBAnKrNPDf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Mount Google Drive and Load Data\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset path\n",
        "data_dir = '/content/drive/MyDrive/Fundus_Dataset'  # Update to your dataset path\n",
        "if not os.path.exists(data_dir):\n",
        "    raise Exception(f\"Dataset folder {data_dir} not found.\")\n",
        "\n",
        "# Image parameters\n",
        "img_height, img_width = 224, 224  # ResNet152 default input size\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2,\n",
        "    preprocessing_function=tf.keras.applications.resnet.preprocess_input  # ResNet-specific preprocessing\n",
        ")\n",
        "\n",
        "# Training and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Display class names\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "print(\"Class names:\", class_names)\n",
        "print(\"Training samples:\", train_generator.samples)\n",
        "print(\"Validation samples:\", val_generator.samples)"
      ],
      "metadata": {
        "id": "ATUQiGBzPFnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define and Configure ResNet152"
      ],
      "metadata": {
        "id": "cCaXWV7LPHFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define ResNet152 Model\n",
        "def create_resnet152_model(num_classes):\n",
        "    # Load pre-trained ResNet152 with ImageNet weights\n",
        "    base_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Add custom classification head\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_resnet152_model(num_classes)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HnHE0uiYPJg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Train the Model"
      ],
      "metadata": {
        "id": "eJAv5A1oPK2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Train the Model\n",
        "epochs = 20  # Adjust based on convergence\n",
        "\n",
        "# Callbacks for training\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/resnet152_fundus_best.h5',\n",
        "                                       monitor='val_accuracy', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Fine-tune (unfreeze some layers)\n",
        "base_model = model.layers[0]\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:  # Fine-tune last 20 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile with lower learning rate\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Continue training\n",
        "fine_tune_epochs = 10\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    epochs=fine_tune_epochs,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Save final model\n",
        "model.save('/content/drive/MyDrive/resnet152_fundus_final.h5')"
      ],
      "metadata": {
        "id": "7vnF9ZJnPM-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluate and Visualize Results"
      ],
      "metadata": {
        "id": "x9W972HLPOtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Evaluate and Visualize\n",
        "# Combine histories\n",
        "acc = history.history['accuracy'] + history_fine.history['accuracy']\n",
        "val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
        "loss = history.history['loss'] + history_fine.history['loss']\n",
        "val_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "val_generator.reset()\n",
        "preds = np.argmax(model.predict(val_generator), axis=1)\n",
        "true_labels = val_generator.classes\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s60Fz1n1PQ-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Test a Single Image"
      ],
      "metadata": {
        "id": "w6gkQPzmPSl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Test a Single Image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_image(image_path):\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.resnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    pred = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(pred)]\n",
        "    return img, predicted_class\n",
        "\n",
        "# Example usage\n",
        "test_image_path = '/content/drive/MyDrive/Fundus_Dataset/Severe/sample.jpg'  # Update path\n",
        "img, pred_class = predict_image(test_image_path)\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted: {pred_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFWP2BbqPVV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Convert to TensorFlow Lite for Edge Deployment"
      ],
      "metadata": {
        "id": "_W6jxbmvP5Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: TensorFlow Lite Conversion\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Apply default optimizations (quantization)\n",
        "converter.target_spec.supported_types = [tf.float16]  # Use float16 for reduced size\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "tflite_path = '/content/drive/MyDrive/resnet152_fundus.tflite'\n",
        "with open(tflite_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"TFLite model saved to {tflite_path}\")\n",
        "print(f\"Size of TFLite model: {os.path.getsize(tflite_path) / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "# Test TFLite inference\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Example inference on a single image\n",
        "test_image = load_img('/content/drive/MyDrive/Fundus_Dataset/Severe/sample.jpg', target_size=(224, 224))\n",
        "test_image_array = img_to_array(test_image)\n",
        "test_image_array = tf.keras.applications.resnet.preprocess_input(test_image_array)\n",
        "test_image_array = np.expand_dims(test_image_array, axis=0).astype(np.float32)\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], test_image_array)\n",
        "interpreter.invoke()\n",
        "tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
        "tflite_pred_class = class_names[np.argmax(tflite_output[0])]\n",
        "print(f\"TFLite Predicted Class: {tflite_pred_class}\")\n",
        "plt.imshow(test_image)\n",
        "plt.title(f\"TFLite Predicted: {tflite_pred_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PW-Xp95gP5zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Compute Advanced Evaluation Metrics"
      ],
      "metadata": {
        "id": "ZRZQNFJ8P7J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Advanced Evaluation Metrics\n",
        "val_generator.reset()\n",
        "y_true = val_generator.classes\n",
        "y_pred_probs = model.predict(val_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Precision, Recall, F1-Score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f\"Precision (weighted): {precision:.4f}\")\n",
        "print(f\"Recall (weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (weighted): {f1:.4f}\")\n",
        "\n",
        "# ROC Curve and AUC for each class\n",
        "y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i in range(num_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Multi-Class Classification')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6jSH7t-eP92O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Test a Single Image (Keras Model)"
      ],
      "metadata": {
        "id": "JgU98aoTP_z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Test a Single Image (Keras)\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_image(image_path):\n",
        "    img = load_img(image_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.keras.applications.resnet.preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    pred = model.predict(img_array)\n",
        "    predicted_class = class_names[np.argmax(pred)]\n",
        "    return img, predicted_class\n",
        "\n",
        "test_image_path = '/content/drive/MyDrive/Fundus_Dataset/Severe/sample.jpg'\n",
        "img, pred_class = predict_image(test_image_path)\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Predicted: {pred_class}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z-tvPWqtQBmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes"
      ],
      "metadata": {
        "id": "jcrGO0jVQIcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes\n",
        "TFLite Size: Float16 quantization halves the model size; further reduction (e.g., int8) is possible but may trade off accuracy.\n",
        "Evaluation: Advanced metrics complement accuracy and confusion matrix, offering insights into false positives/negatives, vital for fundus classification.\n",
        "Dataset: Assumes 3,700 images in Fundus_Dataset with 5 subfolders. Update paths and class names if different.\n",
        "Running Instructions\n",
        "Upload your dataset to Google Drive.\n",
        "Enable GPU in Colab (Runtime > Change runtime type > GPU).\n",
        "Run cells sequentially; adjust data_dir and test_image_path as needed.\n",
        "Expect high accuracy (92-95%) with fine-tuning, though TFLite may slightly reduce it due to quantization."
      ],
      "metadata": {
        "id": "Go4ccHfiQDeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "rb40V15TQKdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Features and Notes"
      ],
      "metadata": {
        "id": "m5UrFIJIPWju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Features and Notes\n",
        "ResNet152: Pre-trained on ImageNet, with a custom head for 5-class classification. Residual connections ensure high accuracy by mitigating vanishing gradients.\n",
        "Transfer Learning: Initial training with frozen base layers, followed by fine-tuning of the last 20 layers for fundus-specific features.\n",
        "Data Augmentation: Applied to prevent overfitting on the relatively small dataset (3,700 images).\n",
        "GPU Utilization: Optimized for Colab’s GPU to handle ResNet152’s computational demands (~60M parameters, ~230 MB size).\n",
        "Evaluation: Includes accuracy, loss plots, and a confusion matrix for detailed performance analysis.\n",
        "Dataset: Assumes 3,700 images in /content/drive/MyDrive/Fundus_Dataset with subfolders for each class. Adjust paths if different.\n",
        "Assumptions\n",
        "Dataset is balanced or nearly balanced across 5 classes (e.g., ~740 images per class). If imbalanced, add class weights to the model.compile loss function.\n",
        "Images are RGB fundus photographs in standard formats (e.g., JPG, PNG).\n",
        "Running in Colab\n",
        "Upload your dataset to Google Drive.\n",
        "Copy this code into a Colab notebook.\n",
        "Update data_dir and test_image_path to match your file structure.\n",
        "Run cells sequentially; ensure GPU runtime is enabled (Runtime > Change runtime type > GPU).\n",
        "Expected Accuracy\n",
        "ResNet152 typically achieves >90% accuracy on medical imaging tasks with fine-tuning, potentially reaching 92-95% on this dataset, depending on image quality and preprocessing. The two-phase training (transfer learning + fine-tuning) maximizes performance."
      ],
      "metadata": {
        "id": "8aaeoeZJPYuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "mpECWASWQMDd"
      }
    }
  ]
}